{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Linear Algebra for programmers, part 1\"\n",
    "description: \" From notation to meaning.\"\n",
    "date: \"2023-08-27\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing about reading this blog post is to not get scared off by the formulas. The post may look like all the crap you normally skim over, so you may be tempted to skim over this one. Don't. __None of this is hard.__ Just read the post top to bottom, and I promise you every individual step and the whole thing put together will make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highschool math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hight school your math teacher may have started a treatment of linear algebra by making you solve a system of linear equations, at which point you very sensibly zoned out because you knew you'd go on to program computers and never have to solve a system of linear equations again (don't worry, I won't be talking much about them here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "0x_1 + 1x_2 = 0\\\\\n",
    "-1x_1 - 0x_2 = 0\n",
    "\\end{eqnarray}\n",
    "\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also may have learned that for some reason you can take the coefficients and put them in a 2D array like this:\n",
    "$A=\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "-1 & 0 \\\\\n",
    "\\end{bmatrix}$.\n",
    "You've now defined a matrix $A$, and you can re-express the system of linear equations above as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand\\qvec[1]{\\begin{bmatrix}#1\\end{bmatrix}}\n",
    "A\\qvec{x_1\\\\x_2}=0\n",
    "\\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're _really_ hellbent on cleaning things up, you can express the vector $\\qvec{x_1, x_2}$ as $x=\\qvec{x_1 \\\\ x_2}$, which now gives you a really clean equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Ax=0\n",
    "\\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equations 1 - 3 are just different ways to say the exact same thing. In different situations you may prefer one notation over another, but there is no material difference between them. They are all equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll talk about what matrix-vector multiplication _means_ in a moment. For now let's look at how the operation is defined. The precise definition of matrix-vector multiplication flows out of the notation above, so you never again have to look it up on wikipedia. If you need to multiply a matrix by a vector, say $\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "-1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\qvec{1 \\\\ 2}$, just recall that this is equivalent to the left side of the system of equations above. So you take the $\\qvec{1, 2}$ vector, jam it into every row, and add up the columns:\n",
    "$$\n",
    "\\qvec{\n",
    "0*1 + 1*2\\\\\n",
    "-1*1 - 0*2\n",
    "}=\\qvec{2 \\\\ -1}\n",
    "$$\n",
    "\n",
    "\"Jam it into every row and add up the columns\" is a slightly less formal way of saying \"dot product\"-- the sum of the pairwise multiplication of elements of two vectors. We obtain the result $\\qvec{2, -1}$ by computing the dot product of $\\qvec{1, 2}$ with every row of $A$.\n",
    "\n",
    "(This in itself is curious. The dot product of two vectors represents the degree to which they point in the same direction. What does that have to do with linear equations or rows of a matrix in matrix-vector multiplication? I will not be answering this question here, but hope to get to it in a future post.)\n",
    "\n",
    "If you forget how this works, just think of converting the matrix-vector multiplication notation back into the linear equation system notation again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices as functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what matrix-vector multiplication means. This blew my mind when I first learned about it. You can think of a matrix as a function, and you can think of multiplying a matrix by a vector as applying that function to the vector. So when you see $Ax$, autocomplete it in your head to \"calling some function $A$ with argument $x$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually not so strange-- you can think of many structures as functions. For example, you can think of a number $3$ as a function. When you multiply it by things, it makes them three times bigger. Thinking about matrices this way happens to be very convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that $Ax=0$ denotes both the linear system in equation 1, and a call to a function $A$ with argument $x$ (getting the zero vector in return) leads to a curious insight about the relationship between high school math and programming.\n",
    "\n",
    "In high school you're given equations and asked to find their roots. We already established that a system of equations is equivalent to matrix-vector multiplication, which can be thought of as function application. And so, in high school you're _given_ a function $A$ along with its output, and asked to _find_ the inputs that match that output.\n",
    "\n",
    "Programming is usually the exact opposite. In programming what you're _given_ is the shape of inputs and outputs, and your job is to _construct_ a function $A$ that converts one to the other. The computer then executes the functions you construct, often at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do matrices do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to cover matrix-matrix multiplication, what it means, and how it works. Suppose we have two matrices, $M$ and $N$, and a vector $x$. What does $MNx$ mean? What helps to think about this problem is that matrix multiplication is assosiative:\n",
    "$$\n",
    "(MN)x=M(Nx)\n",
    "\\tag{5}\n",
    "$$\n",
    "On the righthand side, $Nx$ returns a vector, which we then multiply by $M$. Thinking of matrices as functions, if we have two functions, $m$ and $n$ that simply multiply the corresponding matrix by their argument, then $M(Nx)$ is nothing more than $m(n(x))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example of matrix-vector multiplication:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "-1 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "\\qvec{1 \\\\ 2}\n",
    "=\\qvec{2 \\\\ -1 \\\\ 0}\\tag{4}$$\n",
    "\n",
    "Let's call the matrix on the left $M$. In the equation above we get our result by performing the dot product of $\\qvec{1, 2}$ with every row of $M$. In other words, we treat each row of $M$ as a vector, perform a pairwise multiplication of its elements with $\\qvec{1, 2}$, and sum them.\n",
    "\n",
    "Since you can't perform a dot product of two vectors with different dimensions, for matrix-vector multiplication to work the number of elements in $\\qvec{1, 2}$ must be equal to the number of columns in $M$. Switching to thinking of $M$ as a function, _we've now learned something about the type of its input_. $M$'s arguments _must_ be vectors of two dimensions.\n",
    "\n",
    "The opposite is true for $M$'s rows. Because we perform a dot product of $\\qvec{1, 2}$ with every row of $M$ and $M$ has three rows, the output vector must necessarily have three elements. And so, the number of rows in $M$ tells us about the type of its output.\n",
    "\n",
    "Here is a simple way of expressing this in typescript:\n",
    "\n",
    "```ts\n",
    "type C = [number, number];\n",
    "type R = [number, number, number];\n",
    "\n",
    "let M = (in: C) -> R {\n",
    "  // ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal with these series is to give you an intuitive understanding of common linear algebra concepts, so that when you encounter them, you can have a good sense of what they mean and not be completely lost. This post should give you an intuition for matrices, matrix multiplication, what it means, and how it works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
